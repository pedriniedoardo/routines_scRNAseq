# AIM ---------------------------------------------------------------------
# Apply the filter stated in the label of the file.
# This is either a testing of the filtering results, or the actual filtering choice to go forward

# libraries ---------------------------------------------------------------
library(scater)
library(Seurat)
library(tidyverse)
library(robustbase)
library(patchwork)
# library(DoubletFinder)
library(scDblFinder)

# specify the version of Seurat Assay -------------------------------------
# set seurat compatible with seurat4 workflow
options(Seurat.object.assay.version = "v5")
options(future.globals.maxSize = 1000 * 1024^2)

# define the filtering parameters -----------------------------------------
featureLow_thr <- 1000
featureHigh_thr <- 7000
mito_thr <- 10

# build the label
label <- paste(featureLow_thr,featureHigh_thr,mito_thr,"V5",sep = "_")

# read in the data --------------------------------------------------------
# location of all the raw matrices
folder <- "../../data/SopuX_out/"
id_sample <- dir(folder)

# load the LUT of the dataset
LUT <- read_csv("../../data/LUT_sample.csv")

# load the LUT of the doublet rate estimate
# df_doublet <- read_csv("../data/dublets_rate_2023.csv")

# load the automatic annotation provided by cellranger
list_annotation <- lapply(id_sample,function(x){
  file_id <- paste0("../../out/cellranger901/",x,"/outs/cell_types/cell_types.csv")
  read_csv(file_id) %>%
    column_to_rownames("barcode")
}) %>%
  setNames(id_sample)

# run the processing ------------------------------------------------------
# do the preprocessing over all the dataset and save the objects
# x <- "test_neuron_auto"
list_datasc <- lapply(id_sample,function(x){
  # to track the processing of the progress of the lapply
  print(x)
  
  # read in the matrix
  data <- Read10X(data.dir = paste0(folder,x))
  
  # crete the object
  datasc <- CreateSeuratObject(counts = data, project = LUT %>%
                                 filter(sample_id == x) %>%
                                 pull(sample_name), min.cells = 20, min.features = 200)
  
  # add the metadata
  # datasc$percent.mt <- PercentageFeatureSet(datasc, pattern = "^MT-")
  # datasc$percent.ribo <- PercentageFeatureSet(datasc, pattern = "^RP[SL][[:digit:]]|^RPLP[[:digit:]]|^RPSA")
  datasc$percent.mt <- PercentageFeatureSet(datasc, pattern = "^mt-")
  datasc$percent.ribo <- PercentageFeatureSet(datasc, pattern = "^Rp[sl][[:digit:]]|^Rplp[[:digit:]]|^Rpsa")
  # add also the percentage of globin. in this dataset it is not meaningful as there is no blood
  # datasc$percent.globin <- Seurat::PercentageFeatureSet(datasc,pattern = "^HB[^(P)]")
  datasc$percent.globin <- Seurat::PercentageFeatureSet(datasc,pattern = "^Hb[^(p)]")
  
  # label the cells based on the mt reads content
  datasc$mt_bin <- datasc@meta.data %>%
    mutate(test = case_when(percent.mt < 1~"low",
                            percent.mt < 10~"mid",
                            T ~ "high")) %>%
    pull(test)
  
  # datasc$treat <- LUT %>%
  #   filter(sample_id == x) %>%
  #   pull(status)
  # 
  # datasc$ID <- LUT %>%
  #   filter(sample_id == x) %>%
  #   pull(sample_id)
  
  # add the autimatic annotation generated by cellranger to the object
  datasc <- AddMetaData(datasc,list_annotation[[x]])
  
  # add the filtering variable based on the fixed threshold
  datasc$discard_threshold <- datasc@meta.data %>%
    mutate(test = percent.mt > mito_thr | nFeature_RNA < featureLow_thr | nFeature_RNA > featureHigh_thr) %>% 
    pull(test)
  
  # add the filtering variable based on the adaptive threshold, multivariable
  # library(robustbase)
  # library(scater)
  stats <- cbind(log10(datasc@meta.data$nCount_RNA),
                 log10(datasc@meta.data$nFeature_RNA),
                 datasc@meta.data$percent.mt)
  
  outlying <- adjOutlyingness(stats, only.outlyingness = TRUE)
  multi.outlier <- isOutlier(outlying, type = "higher")
  datasc$discard_multi <- as.vector(multi.outlier)
  
  # add the filtering variable based on the adaptive threshold single variable
  high_QC_mito <- isOutlier(datasc@meta.data$percent.mt, type="high", log=TRUE)
  QC_features <- isOutlier(datasc@meta.data$nFeature_RNA, type="both", log=TRUE)
  
  datasc$discard_single <- high_QC_mito | QC_features
  
  return(datasc)
}) %>%
  setNames(id_sample)

# confirm the class of the objects ----------------------------------------
lapply(list_datasc, function(x){
  class(x@assays$RNA)
})

# check the full metadata
meta_total <- lapply(list_datasc, function(x){
  x@meta.data %>%
    rownames_to_column("barcode") %>%
    mutate(barcode = paste0(barcode,"|",orig.ident))
}) %>%
  bind_rows(.id = "dataset")

# count the cells in total
meta_total %>%
  dplyr::count(dataset)

# count the cells that will pass the filtes
meta_total %>%
  group_by(dataset,discard_threshold) %>%
  summarise(n = n(),.groups = "drop") %>%
  group_by(dataset) %>%
  mutate(tot = sum(n))

# check if some cells have low coverage
meta_total %>%
  filter(nCount_RNA <= 500)

# doublet detection -------------------------------------------------------
list_datasc_doublet <- lapply(list_datasc,function(scobj){
  # preprocess the dataset before the doublet identification as recommended in:
  # https://bioconductor.org/packages/release/bioc/vignettes/scDblFinder/inst/doc/scDblFinder.html
  # 1.5.11
  # according to the documentation the doublet identification should be run before the fine filtering
  # remove low coverage cells and proprocess to generata clusters needed for the doublet identification
  scobj <- subset(scobj,subset = nCount_RNA > 500) %>%
    NormalizeData() %>%
    FindVariableFeatures(selection.method = "vst", nfeatures = 2000) %>%
    ScaleData() %>%
    RunPCA() %>%
    FindNeighbors(dims = 1:30) %>%
    FindClusters() %>%
    # do I run the UMAP ? I do not need it for the doublet identification, but can be useful in case someone wants to explore an individual sample
    RunUMAP(dims = 1:30)
  
  # run scDblFinder after filtering the low coverage cells
  sce_scobj <- scDblFinder(GetAssayData(scobj, layer="counts"), clusters=Idents(scobj))
  
  # port the resulting scores back to the Seurat object:
  scobj$scDblFinder.score <- sce_scobj$scDblFinder.score
  scobj$scDblFinder.class <- sce_scobj$scDblFinder.class
  
  return(scobj)
})

# save the list of objects before fixed threshold removal but after doublet detection
saveRDS(object = list_datasc_doublet,file = "../../out/R_analysis/object/02_list_datasc_SoupX_beforeQC.rds")

# check the numbers after fixed threshold filtering
lapply(list_datasc_doublet, function(x){
  dim(x)
})

# filter based on QC ------------------------------------------------------
list_datasc_doublet_fixed <- lapply(list_datasc_doublet,function(scobj){
  
  # perform the filtering based on the fixed threshold defined
  scobj_filter <- subset(scobj, subset = discard_threshold == 0)
  
  return(scobj_filter)
})

# save the list of objects before fixed threshold removal
saveRDS(object = list_datasc_doublet_fixed,file = paste0("../../out/R_analysis/object/02_list_datasc_SoupX_afterQC_",label,"_doublet.rds"))

# check the numbers after fixed threshold filtering
lapply(list_datasc_doublet_fixed, function(x){
  dim(x)
})

# extract the metadata from each dataset
meta_doublet_fixed <- lapply(list_datasc_doublet_fixed, function(x){
  x@meta.data %>%
    rownames_to_column("barcode") %>%
    mutate(barcode = paste0(barcode,"|",orig.ident)) %>%
    mutate(tot_nFeature = rownames(x) %>% length())
}) %>%
  bind_rows(.id = "dataset")

meta_doublet_fixed %>%
  write_tsv("../../out/R_analysis/table/02_meta_datasc_afterQCDoublet_V5.tsv")

# filter based on doublet -------------------------------------------------
# scobj <- list_datasc_doublet_fixed$SacsKO5mo_MG
list_datasc_singlet_fixed <- lapply(list_datasc_doublet_fixed,function(scobj){
  
  # perform the filtering based on the fixed threshold defined
  scobj_filter <- subset(scobj, subset = scDblFinder.class == "singlet")
  
  return(scobj_filter)
})

# save the list of objects before fixed threshold removal
saveRDS(object = list_datasc_singlet_fixed,file = paste0("../../out/R_analysis/object/02_list_datasc_SoupX_afterQC_",label,"_singlet.rds"))

# check the numbers after fixed threshold filtering
lapply(list_datasc_singlet_fixed, function(x){
  dim(x)
})

# check the numbers before filtering
lapply(list_datasc_doublet_fixed, function(x){
  x@meta.data %>%
    group_by(scDblFinder.class) %>%
    summarise(n = n(),.groups = "drop")
})

# extract the metadata from each dataset
meta_singlet_fixed <- lapply(list_datasc_singlet_fixed, function(x){
  x@meta.data %>%
    rownames_to_column("barcode") %>%
    mutate(barcode = paste0(barcode,"|",orig.ident)) %>%
    mutate(tot_nFeature = rownames(x) %>% length())
}) %>%
  bind_rows(.id = "dataset")

meta_singlet_fixed %>%
  write_tsv("../../out/R_analysis/table/02_meta_datasc_afterQCSinglet_V5.tsv")
